{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "breathing-bobby",
   "metadata": {},
   "source": [
    "# Compilation of Code Snippets for Data Science\n",
    "\n",
    "All you need is here (and google everything else)\n",
    "\n",
    "Good luck for the test!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-classroom",
   "metadata": {},
   "source": [
    "## 1. Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-canvas",
   "metadata": {},
   "source": [
    "## 2. Pandas DataFrame\n",
    "\n",
    "2.1. Create a `DataFrame` from a `Dictionary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tight-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stalls</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Spine</td>\n",
       "      <td>20</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Koufu</td>\n",
       "      <td>15</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canteen 9</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Hill</td>\n",
       "      <td>12</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canteen 11</td>\n",
       "      <td>8</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Canteen 13</td>\n",
       "      <td>6</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Canteen 14</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Canteen 16</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Stalls  Rating\n",
       "0  North Spine      20     4.5\n",
       "1        Koufu      15     4.2\n",
       "2    Canteen 9      10     4.0\n",
       "3   North Hill      12     3.7\n",
       "4   Canteen 11       8     4.2\n",
       "5   Canteen 13       6     2.9\n",
       "6   Canteen 14       4     4.7\n",
       "7   Canteen 16       2     4.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canteens_dict = {\"Name\" : [\"North Spine\", \"Koufu\", \"Canteen 9\", \"North Hill\", \"Canteen 11\", \"Canteen 13\", \"Canteen 14\", \"Canteen 16\"],\n",
    "                 \"Stalls\" : [20, 15, 10, 12, 8, 6, 4, 2],\n",
    "                 \"Rating\" : [4.5, 4.2, 4.0, 3.7, 4.2, 2.9, 4.7, 4.1]\n",
    "                }\n",
    "\n",
    "canteens_df = pd.DataFrame(canteens_dict)\n",
    "canteens_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-trash",
   "metadata": {},
   "source": [
    "2.1.1. Create a copy of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteens_df2 = canteens_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-insight",
   "metadata": {},
   "source": [
    "2.2. Extract rows\n",
    "\n",
    "2.2.1. Extract a single row from a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteens_df.iloc[0]\n",
    "canteens_df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-certification",
   "metadata": {},
   "source": [
    "2.2.2. Extract multiple rows as a `DataFrame` by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteens_df.loc[[1,3,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-enemy",
   "metadata": {},
   "source": [
    "2.2.3. Extract rows as a `DataFrame` by matching values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmndata_pred = pkmndata[pkmndata[\"Name\"].isin([\"Charizard\", \"Snorlax\", \"Vivillon\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-recall",
   "metadata": {},
   "source": [
    "2.3. Print rows from a `DataFrame`\n",
    "* head() outputs the first 5 rows\n",
    "* head(x) outputs the first x rows\n",
    "* tail() outputs the last _ rows\n",
    "* sample(x) outputs x randomly selected rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteens_df.head()\n",
    "canteens_df.tail()\n",
    "canteens_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-integral",
   "metadata": {},
   "source": [
    "2.4. Check the _data type_ and _dimensions_ (rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(canteens_df))\n",
    "print(\"Data dimensions : \", canteens_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-producer",
   "metadata": {},
   "source": [
    "2.5. Check data types of variables (cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(canteens_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-divide",
   "metadata": {},
   "source": [
    "2.6. Display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset settings\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-holocaust",
   "metadata": {},
   "source": [
    "2.7. Remove rows/columns\n",
    "\n",
    "2.7.1. Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Id', 'MSSubClass', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'MoSold', 'YrSold', 'GarageYrBlt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-midwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dressed-eight",
   "metadata": {},
   "source": [
    "2.8. Convert a variable into \"category\" data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to category data type: By converting an existing column to a category dtype:\n",
    "houseCatData['MSSubClass'] = houseCatData['MSSubClass'].astype(\"category\")\n",
    "\n",
    "# Change to category data type: By specifying dtype when constructing a Series\n",
    "msc = pd.Series(houseCatData['MSSubClass'], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-friday",
   "metadata": {},
   "source": [
    "## 3. Import file into a DataFrame\n",
    "\n",
    "3.1. CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('somedata.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-practitioner",
   "metadata": {},
   "source": [
    "3.2. TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = pd.read_table('somedata.txt', sep = \"\\s+\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-creator",
   "metadata": {},
   "source": [
    "3.3. XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_data = pd.read_excel('somedata.xlsx', sheet_name = 'Sheet1', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-parallel",
   "metadata": {},
   "source": [
    "3.4. JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pd.read_json('somedata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-housing",
   "metadata": {},
   "source": [
    "3.5. HTML\n",
    "\n",
    "- For use if the dataset is in a table formal within an HTML website.\n",
    "\n",
    "In this example, we try to get the cast of Kung-Fu Panda from http://www.imdb.com/title/tt0441773/fullcredits/?ref_=tt_ov_st_sm\n",
    "\n",
    "html_data will be a list of DataFrames, each DataFrame derived from a table within that HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = pd.read_html('http://www.imdb.com/title/tt0441773/fullcredits/?ref_=tt_ov_st_sm')\n",
    "print(\"HTML tables : \", len(html_data))\n",
    "print(type(html_data[2]))\n",
    "html_data[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-sperm",
   "metadata": {},
   "source": [
    "## 4. Statistics for Variables in a DataFrame\n",
    "\n",
    "for Numeric Data\n",
    "\n",
    "### 4.1. Uni-Variate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-firewall",
   "metadata": {},
   "source": [
    "4.1.1. Extract a single variable as a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = pd.DataFrame(pkmndata['HP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-health",
   "metadata": {},
   "source": [
    "4.1.2. Check _data type_ and _size of dataset_ (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(hp))\n",
    "print(\"Data dims : \", hp.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-chest",
   "metadata": {},
   "source": [
    "4.1.3. Check summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-zoning",
   "metadata": {},
   "source": [
    "### 4.2. Multi-Variate Statistics\n",
    "\n",
    "4.2.1. Extract multiple variables to a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-grounds",
   "metadata": {},
   "source": [
    "4.2.2. Check summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-horizon",
   "metadata": {},
   "source": [
    "4.2.3. Check information about the `DataFrame` and its variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-messaging",
   "metadata": {},
   "source": [
    "4.2.4. Check 'skewness' of each variable's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-roman",
   "metadata": {},
   "source": [
    "## 5. Visualisation with Plots\n",
    "\n",
    "for Numeric data\n",
    "\n",
    "### 5.1. Uni-Variate Plots\n",
    "\n",
    "5.1.1. Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(24, 4))\n",
    "sb.boxplot(data = hp, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-plenty",
   "metadata": {},
   "source": [
    "5.1.2. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.histplot(data = hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-planning",
   "metadata": {},
   "source": [
    "5.1.3. Kernel Density Estimate (KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.kdeplot(data = hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-travel",
   "metadata": {},
   "source": [
    "5.1.4. Histogram and KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.histplot(data = hp, kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-matthew",
   "metadata": {},
   "source": [
    "5.1.5. Violin Plot - combines boxplot and KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.violinplot(data = hp, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-belly",
   "metadata": {},
   "source": [
    "### 5.2. Bi-Variate Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-league",
   "metadata": {},
   "source": [
    "5.2.1. Jointplot\n",
    "* concatenate two variables together first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF = pd.concat([attack, hp], axis = 1).reindex(attack.index)\n",
    "sb.jointplot(data = jointDF, x = \"Attack\", y = \"HP\", height = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-grace",
   "metadata": {},
   "source": [
    "5.2.2. Heatmap: shows correlation between two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF.corr() # just a normal DataFrame of the correlation\n",
    "\n",
    "sb.heatmap(jointDF.corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-journey",
   "metadata": {},
   "source": [
    "5.2.3. **Subplots** for single variables in individual `DataFrames`\n",
    "\n",
    "5.2.3.1. 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "sb.boxplot(data = total_train, orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = total_train, ax = axes[1])\n",
    "sb.violinplot(data = total_train, orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-cartoon",
   "metadata": {},
   "source": [
    "5.2.3.2. 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib figure with three subplots (2 rows, 3 cols)\n",
    "f, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Plot the basic uni-variate figures for HP\n",
    "sb.boxplot(data = hp, orient = \"h\", ax = axes[0,0])\n",
    "sb.histplot(data = hp, ax = axes[0,1])\n",
    "sb.violinplot(data = hp, orient = \"h\", ax = axes[0,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for Attack\n",
    "sb.boxplot(data = attack, orient = \"h\", ax = axes[1,0])\n",
    "sb.histplot(data = attack, ax = axes[1,1])\n",
    "sb.violinplot(data = attack, orient = \"h\", ax = axes[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-clearance",
   "metadata": {},
   "source": [
    "### 5.3. Multi-Variate Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-forest",
   "metadata": {},
   "source": [
    "5.3.1. **Subplots** for a multi-variate `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the distributions of all variables (6 rows, 3 cols)\n",
    "f, axes = plt.subplots(6, 3, figsize=(18, 24))\n",
    "\n",
    "count = 0\n",
    "for var in numDF:\n",
    "    sb.boxplot(data = numDF[var], orient = \"h\", ax = axes[count,0])\n",
    "    sb.histplot(data = numDF[var], ax = axes[count,1])\n",
    "    sb.violinplot(data = numDF[var], orient = \"h\", ax = axes[count,2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-friendship",
   "metadata": {},
   "source": [
    "5.3.2. Correlation Matrix & Heatmap\n",
    "\n",
    "5.3.2.1. Whole heatmap (includes all variables in dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "numDF.corr() # just a normal DataFrame of the correlation matrix\n",
    "\n",
    "f = plt.figure(figsize=(12, 12))\n",
    "sb.heatmap(numDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-shark",
   "metadata": {},
   "source": [
    "5.3.2.2. Partial heatmap (only specified variables in groupby included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(17, 12))\n",
    "sb.heatmap(houseCatData.groupby(['MSSubClass', 'OverallQual']).size().unstack(),\\\n",
    "              linewidths=1, annot=True, annot_kws={\"size\": 18}, cmap=\"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-patient",
   "metadata": {},
   "source": [
    "5.3.3. Pairplot: Jointplot but for >2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = numDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-bosnia",
   "metadata": {},
   "source": [
    "### 5.4. Categorical Plots\n",
    "\n",
    "5.4.1. Catplot: Number of data points in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(y = \"Type 1\", data = pkmndata, kind = \"count\", height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-composition",
   "metadata": {},
   "source": [
    "5.4.2. Catplot: Multiple plots of count in each category across a 2nd category\n",
    "\n",
    "In this case:\n",
    "* 1st category = Type 1\n",
    "* 2nd category = Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(y = 'Type 1', data = pkmndata, col = 'Generation', kind = 'count', col_wrap = 2, height = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-graph",
   "metadata": {},
   "source": [
    "5.4.3. Heatmap of the distribution (count) of 2 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 20))\n",
    "sb.heatmap(dualtype_data.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-peripheral",
   "metadata": {},
   "source": [
    "5.4.4. Boxplot: a boxplot for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the numeric data, y is the categorical data\n",
    "f = plt.figure(figsize=(18, 6))\n",
    "sb.boxplot(x = \"Total\", y = \"Legendary\", data = trainDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-general",
   "metadata": {},
   "source": [
    "5.4.5. Swarmplot: a swarmplot for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the numeric data, y is the categorical data\n",
    "f = plt.figure(figsize=(18, 6))\n",
    "sb.swarmplot(x = \"Total\", y = \"Legendary\", data = trainDF, orient = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-heating",
   "metadata": {},
   "source": [
    "## 6. Categorical Data\n",
    "\n",
    "6.1. Number of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Categories:\", len(pkmndata[\"Generation\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-tract",
   "metadata": {},
   "source": [
    "6.2. Number of data points in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pkmndata[\"Generation\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-saturn",
   "metadata": {},
   "source": [
    "6.2.1. Ratio of data points of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-bruce",
   "metadata": {},
   "source": [
    "## 7. Data Cleaning\n",
    "\n",
    "#### 7.1. NULL/NA values\n",
    "\n",
    "7.1.1. Remove NA values or Fill NA values with default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmndata[\"Type 2\"].dropna()\n",
    "pkmndata[\"Type 2\"].fillna(value='hello', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-interaction",
   "metadata": {},
   "source": [
    "7.1.2. Extract null / non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "singletype_data = pkmndata[pkmndata[\"Type 2\"].isnull()]\n",
    "dualtype_data = pkmndata[pkmndata[\"Type 2\"].isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-virginia",
   "metadata": {},
   "source": [
    "7.1.3. Check number of null values for each variable (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmndata_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-rachel",
   "metadata": {},
   "source": [
    "#### 7.2. Duplicate Data\n",
    "\n",
    "7.2.1. Find Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where Variable '#' is duplicated\n",
    "dupid_data = pkmndata[pkmndata.duplicated(\"#\", keep = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-turkish",
   "metadata": {},
   "source": [
    "7.2.2. Group Duplicate Data together and print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemons with Duplicate IDs\n",
    "print(\"Pokemons with Duplicate IDs :\", len(dupid_data))\n",
    "dupids = dupid_data[\"#\"].unique()\n",
    "print(\"Unique Pokemons with DupIDs :\", len(dupids))\n",
    "print()\n",
    "\n",
    "# Group Pokemons with same ID\n",
    "print(\"# \\t Count \\t List of Pokemons with Duplicate IDs\")\n",
    "print()\n",
    "for dupid in dupids:\n",
    "    dupid_list = list(dupid_data[dupid_data[\"#\"] == dupid][\"Name\"])\n",
    "    print(dupid, \"\\t\", len(dupid_list), \"\\t\", dupid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-liberty",
   "metadata": {},
   "source": [
    "#### 7.3. Sort\n",
    "\n",
    "7.3.1. Sort Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in ascending order by Variable \"Name\"\n",
    "dupid_data.sort_values(by = \"Name\")\n",
    "\n",
    "# sort in descending order\n",
    "dupid_data.sort_values(by = \"Name\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-discussion",
   "metadata": {},
   "source": [
    "#### 7.4. Rename a column\n",
    "\n",
    "7.4.1. Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmndata_clean.rename(columns = {'#': 'ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-pencil",
   "metadata": {},
   "source": [
    "7.4.2. Convert Name to Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkmndata_clean.columns = pkmndata_clean.columns.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-bacteria",
   "metadata": {},
   "source": [
    "7.4.3. Replace specified characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg. remove all .\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\".\",\"\")\n",
    "\n",
    "# eg. replace all spaces with _\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-sharp",
   "metadata": {},
   "source": [
    "7.4.4. Using Regular Expression (RegEx) with the `re` library to search and replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# eg. Fix names with extra Extensions\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Forme)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(Hoopa)(.+)',r'\\2', x))\n",
    "\n",
    "# eg. Fix names with Mega in between\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+Mega)(.+)',r'\\1', x))\n",
    "\n",
    "# eg. Remove Blanks from all the Names\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'\\s+','', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-minutes",
   "metadata": {},
   "source": [
    "#### 7.5. Rename a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the variable \"NAME\" of the row index == 7\n",
    "pkmndata_clean.loc[7,\"NAME\"] = \"CharizardMegaX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-category",
   "metadata": {},
   "source": [
    "#### Set a new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change index to variable \"NAME\"\n",
    "pkmndata_clean = pkmndata_clean.set_index('NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-level",
   "metadata": {},
   "source": [
    "## 8. Linear Regression\n",
    "\n",
    "using Scikit-Learn (`sklearn`)\n",
    "\n",
    "8.1. Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "predictors = [\"HP\", \"Attack\", \"Defense\"]\n",
    "y = pd.DataFrame(pkmndata[\"Total\"])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "\n",
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Predict y values (response) corresponding to X (predictors)\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-marker",
   "metadata": {},
   "source": [
    "8.2. Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "# Print the Coefficients against Predictors (for multi-variate linear regression)\n",
    "pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-transition",
   "metadata": {},
   "source": [
    "8.3. Linear Regression Line\n",
    "> Just FYI, not really in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for the Regression line\n",
    "regline_x = X_train\n",
    "regline_y = linreg.intercept_ + linreg.coef_ * X_train\n",
    "\n",
    "# Plot the Linear Regression line on Scatterplot\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.plot(regline_x, regline_y, 'r-', linewidth = 2)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Plot predictions on Scatterplot\n",
    "f = plt.figure(figsize=(8, 18))\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_train_pred)\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-tonight",
   "metadata": {},
   "source": [
    "8.4. Plot Predictions vs. True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-conservation",
   "metadata": {},
   "source": [
    "8.5. Goodness of Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-arrow",
   "metadata": {},
   "source": [
    "### Just copy paste: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"HP\", \"Attack\", \"Defense\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata[\"Total\"])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "print()\n",
    "\n",
    "# Print the Coefficients against Predictors\n",
    "print(pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"]))\n",
    "print()\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-foundation",
   "metadata": {},
   "source": [
    "## 9. Classification Tree\n",
    "\n",
    "using Scikit-Learn (`sklearn`)\n",
    "\n",
    "9.1. Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "predictors = [\"Total\", \"HP\", \"Attack\", \"Defense\"]\n",
    "y = pd.DataFrame(pkmndata[\"Legendary\"])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Check the sample sizes\n",
    "print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-vegetation",
   "metadata": {},
   "source": [
    "9.2. Plot Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns,         # the variables involved in splitting\n",
    "          class_names=[\"Ordinary\",\"Legendary\"])  # the classes to split into"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-tonight",
   "metadata": {},
   "source": [
    "9.3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y values corresponding to X\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-melbourne",
   "metadata": {},
   "source": [
    "9.3. Goodness of Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Confusion matrix rates (on Train Data)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "print(\"True Positive Rate:\\t\", tp/(tp+fn))\n",
    "print(\"True Negative Rate:\\t\", tn/(tn+fp))\n",
    "print(\"False Positive Rate:\\t\", fp/(tn+fp))\n",
    "print(\"False Negative Rate:\\t\", fn/(tp+fn))\n",
    "\n",
    "# Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Confusion matrix rates (on Test Data)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "print(\"True Positive Rate:\\t\", tp/(tp+fn))\n",
    "print(\"True Negative Rate:\\t\", tn/(tn+fp))\n",
    "print(\"False Positive Rate:\\t\", fp/(tn+fp))\n",
    "print(\"False Negative Rate:\\t\", fn/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-persian",
   "metadata": {},
   "source": [
    "9.4. Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual datasets in different plots\n",
    "# Train Data\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})\n",
    "\n",
    "# Test Data\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for both Train and Test in a single plot\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-there",
   "metadata": {},
   "source": [
    "9.5. Prediction of Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(pkmndata_pred[predictors])\n",
    "\n",
    "# Predict Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-entertainment",
   "metadata": {},
   "source": [
    "### Just copy paste: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract Response and Predictors\n",
    "predictors = [\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]\n",
    "\n",
    "y = pd.DataFrame(pkmndata['Type 1'].astype('category'))\n",
    "X = pd.DataFrame(pkmndata[predictors]) \n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trained Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "f = plt.figure(figsize=(12,12))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"Ordinary\",\"Legendary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
